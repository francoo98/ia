{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francoo98/ia/blob/main/tp_clasificaci%C3%B3n_Franco_Ayala_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font style: color='lime'> Clasificación </font>\n",
        "\n",
        "En este colab se van a encontrar con un problema de clasificación con tres posibles salidas, es decir la variable explicada `y` puede tomar tres valores categoricos (cualitativos) en este caso.\n",
        "\n",
        "[Iris dataset](https://raw.githubusercontent.com/amankharwal/Website-data/master/IRIS.csv)\n",
        "\n",
        "Este dataset es un recopilación de datos de flores de 3 tipos: setosa, versicolor, and virginica.\n",
        "\n",
        "La idea es que con las medidas del sepalo (ancho,alto) y del petalo (ancho,alto)\n",
        "podemos entrenar un modelo de clasificación para que aprenda a distinguir entre estos 3 tipos de flores.\n",
        "\n",
        "Para investigar acerca del dataset: [link](https://archive.ics.uci.edu/ml/datasets/iris)"
      ],
      "metadata": {
        "id": "WHlCXWRHnsai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descargamos el dataset"
      ],
      "metadata": {
        "id": "o4HFZbCKo9Id"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24J_HnR-ltt5"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/amankharwal/Website-data/master/IRIS.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspeccionamos el dataset"
      ],
      "metadata": {
        "id": "cevahqgPnqtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "rvxJWxknpFId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = pd.read_csv('IRIS.csv')\n",
        "iris.head(3) #Observamos los 3 primeros registros con la función .head(), también pueden usar .tail() para ver los ultimos"
      ],
      "metadata": {
        "id": "qdaSDPBVpbHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.info()"
      ],
      "metadata": {
        "id": "iu6BIvUaphU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.describe().T"
      ],
      "metadata": {
        "id": "pa0szyZgpuuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Nota:** Podemos observar que las variables explicativas son 4: sepal_length, sepal_width, petal_lenght y petal_width, donde sus datos son del tipo flotantes, sin valores nulos. Estos simplifica el proceso de limpieza de datos. La variable explicada en este caso es species que contiene el nombre de cada especie."
      ],
      "metadata": {
        "id": "LDIj5PyspxrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vemos la cantidad de registros para cada especie\n",
        "iris['species'].value_counts() #también pueden usar el argumento True -> .value_counts(True) para ver de forma proporcional los datos"
      ],
      "metadata": {
        "id": "_Kv5i4mjqdnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(iris['species'],color='green');"
      ],
      "metadata": {
        "id": "xxFcZhQCqolj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Nota:** Observamos que el dataset esta `balanceado`, es decir, tiene la misma cantidad de registros para cada especie lo cual resulta beneficioso para eviatr que el modelo caiga en un mal aprendizaje."
      ],
      "metadata": {
        "id": "yFQW76EtqwyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Podemos usar un pairplot para correlacionar las variables explicativas\n",
        "sns.pairplot(data=iris,hue='species')"
      ],
      "metadata": {
        "id": "a5L7YS-VsGNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Armamos el dataset para entrenar"
      ],
      "metadata": {
        "id": "1m_VDWHBsAos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris.drop(columns='species').to_numpy()\n",
        "y = iris['species'].to_numpy()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.25, random_state=42)\n",
        "\n",
        "print(f\"Set de entenamiento: {Xtrain.shape}, {ytrain.shape}\")\n",
        "print(f\"Set de testeo: {Xtest.shape}, {ytest.shape}\")"
      ],
      "metadata": {
        "id": "cXqE9dS6sebx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamos el modelo Logistic Regression\n",
        "\n",
        "El modelo logistic regression está construido para optimizar los párametros mediante el error de la función `BinaryCrossEntropy` para lo cual sería ideal dos clases.\n",
        "\n",
        "Cuando existen más clases lo que hace es hacer en cada iteración una `clase vs todas las otras`de esta manera conserva el mismo principio.\n",
        "\n",
        "Para setear el algoritmo en sklearn de logistic regression aplicado a multiclase, como en este caso que son 3 clases de flores, usamos el parametro `multi_class: {‘auto’, ‘ovr’, ‘multinomial’}` seteado en 'multinomial'."
      ],
      "metadata": {
        "id": "anYZ_nLQtCd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression(multi_class='multinomial')\n",
        "log_reg.fit(Xtrain,ytrain)"
      ],
      "metadata": {
        "id": "EH9gk8eVt6_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluamos el modelo"
      ],
      "metadata": {
        "id": "UIXvqs-DuXjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics as ms\n",
        "y_pred_logreg = log_reg.predict(Xtest)\n",
        "confusion_matrix = ms.confusion_matrix(y_true = ytest, y_pred = y_pred_logreg)\n",
        "sns.heatmap(confusion_matrix,annot=True,cbar=False,cmap='Dark2')\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"Ground truth labels\")\n",
        "plt.title(\"Confusion Matrix\");"
      ],
      "metadata": {
        "id": "avDcAdCJuZu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_logreg = ms.accuracy_score(y_true = ytest, y_pred = y_pred_logreg)\n",
        "precision_logreg = ms.precision_score(y_true = ytest, y_pred = y_pred_logreg,average='weighted')\n",
        "recall_logreg = ms.recall_score(y_true = ytest, y_pred = y_pred_logreg,average='weighted')\n",
        "f1_logreg = ms.f1_score(y_true = ytest, y_pred = y_pred_logreg,average='weighted')\n",
        "\n",
        "logreg_metrics = {\"Accuracy\":acc_logreg,\n",
        "                  \"Precision\":precision_logreg,\n",
        "                  \"Recall\":recall_logreg,\n",
        "                  \"F1\":f1_logreg}\n",
        "logreg_metrics"
      ],
      "metadata": {
        "id": "bKJ091UmusGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicción\n",
        "\n",
        "Tomamos un conjunto de datos que represente las variables de entradas para ver que nos devuelve el modelo.\n",
        "\n",
        "La idea es simular al modelo tomando datos nuevos, ya sea através de algun sensor de los datos:\n",
        "\n",
        "* sepal_length\n",
        "* sepal_width\n",
        "* petal_length\n",
        "* petal_width"
      ],
      "metadata": {
        "id": "nal3fp3YvZkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creamos datos nuevos\n",
        "X_prueba = np.array([[3.4, 1.9, 1.2, 0.3]]) # en el array tenemos: sepal_length,\tsepal_width,\tpetal_length,\tpetal_width\n",
        "\n",
        "#Luego predecimos\n",
        "y_pred = log_reg.predict(X_prueba)\n",
        "\n",
        "#Observamos la salida\n",
        "print(f\"Predicción del modelo: {y_pred}\")"
      ],
      "metadata": {
        "id": "EXhXjBvTvjiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PF-bQ2kywyAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes\n",
        "\n",
        "Ahora el ejercicio es que repitan la experiencia que se realizó con Logistic Regression.\n",
        "\n",
        "Para eso deben:\n",
        "1. Explorar el dataset por su cuenta.\n",
        "2. Anotar observaciones que ustedes concluyan.\n",
        "3. Armar el dataset para entrenar y testear.\n",
        "4. Implementar el algoritmo de Naive Bayes -> [MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB)\n",
        "5. Evaluarlo con las metricas que hemos visto (ROC-AUC es solo para clasificación binaria).\n",
        "6. Hacer un predicción."
      ],
      "metadata": {
        "id": "6QCJoLDLwt1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2EDEQ6zT_e7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 🦾 **Ejercicio Extra:** Si te animas te dejo el link para implementar un algoritmo de ensamble del tipo *Boosting* en este [link](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html). Podes repetir los pasos igual que en `Naive Bayes` y comparar cuál de los 3 te dio mejores métricas. Suerte 🤙"
      ],
      "metadata": {
        "id": "X5wPtQK_xnJm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ueDGyAL6AEBU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}