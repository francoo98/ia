{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francoo98/ia/blob/main/tp_clasificaci%C3%B3n_Franco_Ayala_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font style: color='lime'> Clasificaci√≥n </font>\n",
        "\n",
        "En este colab se van a encontrar con un problema de clasificaci√≥n con tres posibles salidas, es decir la variable explicada `y` puede tomar tres valores categoricos (cualitativos) en este caso.\n",
        "\n",
        "[Iris dataset](https://raw.githubusercontent.com/amankharwal/Website-data/master/IRIS.csv)\n",
        "\n",
        "Este dataset es un recopilaci√≥n de datos de flores de 3 tipos: setosa, versicolor, and virginica.\n",
        "\n",
        "La idea es que con las medidas del sepalo (ancho,alto) y del petalo (ancho,alto)\n",
        "podemos entrenar un modelo de clasificaci√≥n para que aprenda a distinguir entre estos 3 tipos de flores.\n",
        "\n",
        "Para investigar acerca del dataset: [link](https://archive.ics.uci.edu/ml/datasets/iris)"
      ],
      "metadata": {
        "id": "WHlCXWRHnsai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descargamos el dataset"
      ],
      "metadata": {
        "id": "o4HFZbCKo9Id"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24J_HnR-ltt5"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/amankharwal/Website-data/master/IRIS.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspeccionamos el dataset"
      ],
      "metadata": {
        "id": "cevahqgPnqtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "rvxJWxknpFId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = pd.read_csv('IRIS.csv')\n",
        "iris.head(3) #Observamos los 3 primeros registros con la funci√≥n .head(), tambi√©n pueden usar .tail() para ver los ultimos"
      ],
      "metadata": {
        "id": "qdaSDPBVpbHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.info()"
      ],
      "metadata": {
        "id": "iu6BIvUaphU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.describe().T"
      ],
      "metadata": {
        "id": "pa0szyZgpuuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Nota:** Podemos observar que las variables explicativas son 4: sepal_length, sepal_width, petal_lenght y petal_width, donde sus datos son del tipo flotantes, sin valores nulos. Estos simplifica el proceso de limpieza de datos. La variable explicada en este caso es species que contiene el nombre de cada especie."
      ],
      "metadata": {
        "id": "LDIj5PyspxrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vemos la cantidad de registros para cada especie\n",
        "iris['species'].value_counts() #tambi√©n pueden usar el argumento True -> .value_counts(True) para ver de forma proporcional los datos"
      ],
      "metadata": {
        "id": "_Kv5i4mjqdnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(iris['species'],color='green');"
      ],
      "metadata": {
        "id": "xxFcZhQCqolj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Nota:** Observamos que el dataset esta `balanceado`, es decir, tiene la misma cantidad de registros para cada especie lo cual resulta beneficioso para eviatr que el modelo caiga en un mal aprendizaje."
      ],
      "metadata": {
        "id": "yFQW76EtqwyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Podemos usar un pairplot para correlacionar las variables explicativas\n",
        "sns.pairplot(data=iris,hue='species')"
      ],
      "metadata": {
        "id": "a5L7YS-VsGNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Armamos el dataset para entrenar"
      ],
      "metadata": {
        "id": "1m_VDWHBsAos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris.drop(columns='species').to_numpy()\n",
        "y = iris['species'].to_numpy()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.25, random_state=42)\n",
        "\n",
        "print(f\"Set de entenamiento: {Xtrain.shape}, {ytrain.shape}\")\n",
        "print(f\"Set de testeo: {Xtest.shape}, {ytest.shape}\")"
      ],
      "metadata": {
        "id": "cXqE9dS6sebx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamos el modelo Logistic Regression\n",
        "\n",
        "El modelo logistic regression est√° construido para optimizar los p√°rametros mediante el error de la funci√≥n `BinaryCrossEntropy` para lo cual ser√≠a ideal dos clases.\n",
        "\n",
        "Cuando existen m√°s clases lo que hace es hacer en cada iteraci√≥n una `clase vs todas las otras`de esta manera conserva el mismo principio.\n",
        "\n",
        "Para setear el algoritmo en sklearn de logistic regression aplicado a multiclase, como en este caso que son 3 clases de flores, usamos el parametro `multi_class: {‚Äòauto‚Äô, ‚Äòovr‚Äô, ‚Äòmultinomial‚Äô}` seteado en 'multinomial'."
      ],
      "metadata": {
        "id": "anYZ_nLQtCd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression(multi_class='multinomial')\n",
        "log_reg.fit(Xtrain,ytrain)"
      ],
      "metadata": {
        "id": "EH9gk8eVt6_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluamos el modelo"
      ],
      "metadata": {
        "id": "UIXvqs-DuXjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics as ms\n",
        "y_pred_logreg = log_reg.predict(Xtest)\n",
        "confusion_matrix = ms.confusion_matrix(y_true = ytest, y_pred = y_pred_logreg)\n",
        "sns.heatmap(confusion_matrix,annot=True,cbar=False,cmap='Dark2')\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"Ground truth labels\")\n",
        "plt.title(\"Confusion Matrix\");"
      ],
      "metadata": {
        "id": "avDcAdCJuZu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_logreg = ms.accuracy_score(y_true = ytest, y_pred = y_pred_logreg)\n",
        "precision_logreg = ms.precision_score(y_true = ytest, y_pred = y_pred_logreg,average='weighted')\n",
        "recall_logreg = ms.recall_score(y_true = ytest, y_pred = y_pred_logreg,average='weighted')\n",
        "f1_logreg = ms.f1_score(y_true = ytest, y_pred = y_pred_logreg,average='weighted')\n",
        "\n",
        "logreg_metrics = {\"Accuracy\":acc_logreg,\n",
        "                  \"Precision\":precision_logreg,\n",
        "                  \"Recall\":recall_logreg,\n",
        "                  \"F1\":f1_logreg}\n",
        "logreg_metrics"
      ],
      "metadata": {
        "id": "bKJ091UmusGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicci√≥n\n",
        "\n",
        "Tomamos un conjunto de datos que represente las variables de entradas para ver que nos devuelve el modelo.\n",
        "\n",
        "La idea es simular al modelo tomando datos nuevos, ya sea atrav√©s de algun sensor de los datos:\n",
        "\n",
        "* sepal_length\n",
        "* sepal_width\n",
        "* petal_length\n",
        "* petal_width"
      ],
      "metadata": {
        "id": "nal3fp3YvZkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creamos datos nuevos\n",
        "X_prueba = np.array([[3.4, 1.9, 1.2, 0.3]]) # en el array tenemos: sepal_length,\tsepal_width,\tpetal_length,\tpetal_width\n",
        "\n",
        "#Luego predecimos\n",
        "y_pred = log_reg.predict(X_prueba)\n",
        "\n",
        "#Observamos la salida\n",
        "print(f\"Predicci√≥n del modelo: {y_pred}\")"
      ],
      "metadata": {
        "id": "EXhXjBvTvjiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PF-bQ2kywyAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes\n",
        "\n",
        "Ahora el ejercicio es que repitan la experiencia que se realiz√≥ con Logistic Regression.\n",
        "\n",
        "Para eso deben:\n",
        "1. Explorar el dataset por su cuenta.\n",
        "2. Anotar observaciones que ustedes concluyan.\n",
        "3. Armar el dataset para entrenar y testear.\n",
        "4. Implementar el algoritmo de Naive Bayes -> [MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB)\n",
        "5. Evaluarlo con las metricas que hemos visto (ROC-AUC es solo para clasificaci√≥n binaria).\n",
        "6. Hacer un predicci√≥n."
      ],
      "metadata": {
        "id": "6QCJoLDLwt1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2EDEQ6zT_e7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ü¶æ **Ejercicio Extra:** Si te animas te dejo el link para implementar un algoritmo de ensamble del tipo *Boosting* en este [link](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html). Podes repetir los pasos igual que en `Naive Bayes` y comparar cu√°l de los 3 te dio mejores m√©tricas. Suerte ü§ô"
      ],
      "metadata": {
        "id": "X5wPtQK_xnJm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ueDGyAL6AEBU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}